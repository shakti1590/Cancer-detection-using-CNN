# -*- coding: utf-8 -*-
"""Cancer detection using CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F02vXqLChPvDMf7HgaMuTqH8WuJS4w9Q
"""

import warnings
warnings.filterwarnings("ignore")

#dataset
!wget https://www.dropbox.com/s/jztol5j7hvm2w96/brain_tumor%20data%20set.zip

#unzip dataset
!unzip "/content/brain_tumor data set.zip"
!rm "/content/brain_tumor data set.zip"

#library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import glob
import cv2
import os
import math
import imutils
import shutil

# count the number of images
ROOT_DIR="/content/Brain Tumor Data Set" 
num_of_images ={}  
for dir in os.listdir(ROOT_DIR):
  num_of_images[dir]= len(os.listdir(os.path.join(ROOT_DIR, dir)))
num_of_images

"""We split our data such we have

* 70% for train data
* 15% for Validation
* 15 % for testing
"""

# we create training folder
if not os.path.exists("./train"):
  os.mkdir("./train")
  for dir in os.listdir(ROOT_DIR):
    os.makedirs("./train/"+dir)
    for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR, dir)), size=(math.floor(70/100*num_of_images[dir])-5), replace=False):
      O=os.path.join(ROOT_DIR,dir,img)
      D= os.path.join('./train', dir)
      shutil.copy(O,D)
      os.remove(O)
else:
  print("Train Folder exsist")

#we create validation folder
if not os.path.exists("./val"):
   os.mkdir("./val")
   for dir in os.listdir (ROOT_DIR):
     os.makedirs("./val/"+dir)
     for img in np.random.choice (a=os.listdir (os.path.join(ROOT_DIR, dir) ),size= (math.floor (15/100*num_of_images [dir])-5), replace=False ):
       O = os.path.join(ROOT_DIR, dir, img)
       D= os.path.join('./val', dir)
       shutil.copy(O,D)
       os.remove(O)
else:
  print("Train Folder exsist")

# we create testing folder
if not os.path.exists("./test"):
  os.mkdir("./test")
  for dir in os.listdir (ROOT_DIR):
    os.makedirs("./test/"+dir)
    for img in np.random. choice (a=os.listdir (os.path.join(ROOT_DIR, dir)),size= (math.floor(15/100* num_of_images [dir])-5), replace=False ):
      O= os.path.join(ROOT_DIR, dir, img)
      D= os.path.join('./test', dir)
      shutil.copy(O,D)
      os.remove(O)
else:
  print("Train Folder exsist")

"""Lets build our model"""

import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, MaxPooling2D, GlobalAvgPool2D
from keras.models import Sequential
from keras.preprocessing import image
import keras
from keras.utils import load_img, img_to_array

model=Sequential()
model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu',input_shape=(224,224,3)))
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(units=64, activation='relu'))
model.add(Dropout (rate=0.25))
model.add(Dense (units=1, activation='sigmoid'))
model.compile(loss= keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'] )
model.summary()

"""Train our model"""

train_datagen = image.ImageDataGenerator( 
zoom_range = 0.2, shear_range =  0.2, rescale = 1./255, horizontal_flip=True)
val_datagen = image.ImageDataGenerator (rescale = 1./255)
test_datagen = image.ImageDataGenerator(rescale = 1./255)

train_data = train_datagen.flow_from_directory (directory="/content/train", target_size=(224,224), batch_size=32, class_mode= 'binary')

train_data.class_indices

val_data = val_datagen.flow_from_directory (directory="/content/val", target_size=(224,224), batch_size=32, class_mode = 'binary')

test_data = test_datagen.flow_from_directory (directory="/content/test", target_size=(224,224), batch_size=32, class_mode = 'binary')

from keras.callbacks import ModelCheckpoint, EarlyStopping

#early stopping
es=EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=5, verbose=1, mode='auto')

#model check point
mc = ModelCheckpoint(filepath="best_model.h5", monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')

#putting call back in a list
call_back=[es,mc]

hist = model.fit_generator(generator=train_data, steps_per_epoch= 8, epochs= 10, verbose= 1,
validation_data= val_data,
validation_steps= 16,
callbacks = call_back)

from keras.models import load_model
from keras.preprocessing import image
model=load_model("/content/best_model.h5")

"""Model Accuracy"""

# checking out the accuracy of our model
acc = model.evaluate_generator (generator= test_data) [1]
print (f"The accuracy of your model is = {acc*100} %")

h=hist.history
h.keys()

plt.plot(h['accuracy']) 
plt.plot(h['val_accuracy'], c = "red")
plt.title("acc vs v-acc")
plt.show()

plt.plot(h['loss'])
plt.plot(h['val_loss'], c = "red")
plt.title("loss vs v-loss")
plt.show()

# path for the image to see if it predics correct class
path="/content/val/Healthey/Not Cancer  (1005).jpg"
img = load_img(path, target_size=(224,224))
input_arr = img_to_array(img)/255
input_arr = np.array([input_arr])
input_arr.shape
pred= model.predict(input_arr)[0][0]
print(pred)
if pred <0.5:
  print("The MRI image is of BRAIN TUMOR")
else:
  print("The MRI image is of Healthey brain")

path = "/content/val/Healthey/Not Cancer  (1005).jpg"
img = load_img(path, target_size = (224,224))
input_arr = img_to_array(img)/255
plt.imshow(input_arr)
plt.show()
input_arr.shape
input_arr = np.expand_dims (input_arr, axis= 0)
pred = model.predict (input_arr)[0][0]
print(pred)
if pred == 0:
   print("The MRI is having a Tumor") 
else:
  print("The MRI is not having a Tumor")